from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers import Activation, Dropout, Flatten, Dense
from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from keras.layers.advanced_activations import LeakyReLU, PReLU
from keras.models import load_model
from scipy.misc import imread, imresize
import keras.backend as K
import pandas as pd
import random
###use crop picture

# act = LeakyReLU(alpha=0.5)
act = 'relu'

model = Sequential()
# model.add(Convolution2D(32, 3, 3, input_shape=(3, 150, 150)))
# model.add(Convolution2D(32, 3, 3, input_shape=(150, 150, 3)))
model.add(Convolution2D(128, 4, 4, input_shape=(64, 64, 3)))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(3, 3)))

# model.add(Convolution2D(64, 3, 3))
# model.add(Activation('relu'))
# model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Convolution2D(32, 3, 3))
model.add(Activation('relu'))
model.add(MaxPooling2D(pool_size=(2, 2)))

model.add(Flatten())  # this converts our 3DA feature maps to 1D feature vectors
model.add(Dense(2000))
model.add(Dropout(0.2))
model.add(Activation('relu'))
model.add(Dense(1500))
model.add(Dropout(0.2))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(1000))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(256))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(128))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Dense(64))
model.add(Activation('relu'))
model.add(Dropout(0.2))
model.add(Activation('relu'))
model.add(Dense(32))
model.add(Activation('relu'))
# model.add(Dropout(0.2))
model.add(Dense(19))
model.add(Activation('softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer='Adam',
              metrics=['accuracy','fmeasure','precision','recall'])

# this is the augmentation configuration we will use for training
train_datagen = ImageDataGenerator(
        rescale=1./255
        # ,
        # shear_range=0.2,
        # zoom_range=0.2,
        # horizontal_flip=True
)

# this is the augmentation configuration we will use for testing:
# only rescaling
# test_datagen = ImageDataGenerator(rescale=1./255)

# this is a generator that will read pictures found in
# subfolers of 'data/train', and indefinitely generate
# batches of augmented image data


train_generator = train_datagen.flow_from_directory(
        #'E:/image_workspace/img/img_convert_20170314/Train/',  # this is the target directory
        "E:/cv/tr4/",
        target_size=(64, 64),  # all images will be resized to 150x150
        batch_size=512,
        # color_mode='grayscale',
        class_mode='categorical',
        # save_to_dir='D:/project/image_classification/example/untitled/pic/converted/',
        # save_format='jpeg'
        )  # since we use binary_crossentropy loss, we need binary labels

# this is a similar generator, for validation data
# validation_generator = test_datagen.flow_from_directory(
#         'E:/image_workspace/img2/',
#         target_size=(64, 64),
#         batch_size=512,
#         # color_mode='grayscale',
#         class_mode='categorical'
#
#         # save_to_dir = 'D:/project/image_classification/example/untitled/pic/convert2/',
#         # save_format = 'jpeg'
# )

random.seed(123)

model.fit_generator(
        generator = train_generator,
        samples_per_epoch = 40000,
        nb_epoch = 125,
        # validation_data=validation_generator,
        # nb_val_samples=1200,

        )

model.save('model7_4.h5')
